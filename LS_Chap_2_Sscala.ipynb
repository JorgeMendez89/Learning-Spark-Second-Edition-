{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Spark - Chapter 2 (Scala)\n",
    "## Getting Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://EM2021002778.bosonit.local:4045\n",
       "SparkContext available as 'sc' (version = 3.1.1, master = local[*], app id = local-1620573521717)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.SparkSession\r\n",
       "import org.apache.spark.sql.functions._\r\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.sql.functions._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@523201b7\r\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spark = SparkSession\n",
    ".builder\n",
    ".appName(\"MnMCount\")\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformations, Actions, and Lazy Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions._\r\n",
       "strings: org.apache.spark.sql.DataFrame = [value: string]\r\n",
       "filtered: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [value: string]\r\n",
       "res0: Long = 17\r\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "val strings = spark.read.text(\"./SPARK_README.md\")\n",
    "val filtered = strings.filter(col(\"value\").contains(\"Spark\"))\n",
    "filtered.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting M&Ms for the Cookie Monster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mnmFile: String = C:/Users/jorgedario.mendez/OneDrive - Bosonit/Documentos/3. Libro/LearningSparkV2-master/databricks-datasets/learning-spark-v2/mnm_dataset.csv\r\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Get the M&M data set filename\n",
    "val mnmFile = \"C:/Users/jorgedario.mendez/OneDrive - Bosonit/Documentos/3. Libro/LearningSparkV2-master/databricks-datasets/learning-spark-v2/mnm_dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mnmDF: org.apache.spark.sql.DataFrame = [State: string, Color: string ... 1 more field]\r\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Read the file into a Spark DataFrame\n",
    "val mnmDF = spark.read.format(\"csv\")\n",
    ".option(\"header\", \"true\")\n",
    ".option(\"inferSchema\", \"true\")\n",
    ".load(mnmFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "countMnMDF: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [State: string, Color: string ... 1 more field]\r\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Aggregate counts of all colors and groupBy() State and Color\n",
    "// orderBy() in descending order\n",
    "val countMnMDF = mnmDF\n",
    ".select(\"State\", \"Color\", \"Count\")\n",
    ".groupBy(\"State\", \"Color\")\n",
    ".agg(count(\"Count\").alias(\"Total\"))\n",
    ".orderBy(desc(\"Total\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-----+\n",
      "|State| Color|Total|\n",
      "+-----+------+-----+\n",
      "|   CA|Yellow| 1807|\n",
      "|   WA| Green| 1779|\n",
      "|   OR|Orange| 1743|\n",
      "|   TX| Green| 1737|\n",
      "|   TX|   Red| 1725|\n",
      "|   CA| Green| 1723|\n",
      "|   CO|Yellow| 1721|\n",
      "|   CA| Brown| 1718|\n",
      "|   CO| Green| 1713|\n",
      "|   NV|Orange| 1712|\n",
      "|   TX|Yellow| 1703|\n",
      "|   NV| Green| 1698|\n",
      "|   AZ| Brown| 1698|\n",
      "|   WY| Green| 1695|\n",
      "|   CO|  Blue| 1695|\n",
      "|   NM|   Red| 1690|\n",
      "|   AZ|Orange| 1689|\n",
      "|   NM|Yellow| 1688|\n",
      "|   NM| Brown| 1687|\n",
      "|   UT|Orange| 1684|\n",
      "|   NM| Green| 1682|\n",
      "|   UT|   Red| 1680|\n",
      "|   AZ| Green| 1676|\n",
      "|   NV|Yellow| 1675|\n",
      "|   NV|  Blue| 1673|\n",
      "|   WA|   Red| 1671|\n",
      "|   WY|   Red| 1670|\n",
      "|   WA| Brown| 1669|\n",
      "|   NM|Orange| 1665|\n",
      "|   WY|  Blue| 1664|\n",
      "|   WA|Yellow| 1663|\n",
      "|   WA|Orange| 1658|\n",
      "|   CA|Orange| 1657|\n",
      "|   NV| Brown| 1657|\n",
      "|   CA|   Red| 1656|\n",
      "|   CO| Brown| 1656|\n",
      "|   UT|  Blue| 1655|\n",
      "|   AZ|Yellow| 1654|\n",
      "|   TX|Orange| 1652|\n",
      "|   AZ|   Red| 1648|\n",
      "|   OR|  Blue| 1646|\n",
      "|   OR|   Red| 1645|\n",
      "|   UT|Yellow| 1645|\n",
      "|   CO|Orange| 1642|\n",
      "|   TX| Brown| 1641|\n",
      "|   NM|  Blue| 1638|\n",
      "|   AZ|  Blue| 1636|\n",
      "|   OR| Green| 1634|\n",
      "|   UT| Brown| 1631|\n",
      "|   WY|Yellow| 1626|\n",
      "|   WA|  Blue| 1625|\n",
      "|   CO|   Red| 1624|\n",
      "|   OR| Brown| 1621|\n",
      "|   TX|  Blue| 1614|\n",
      "|   OR|Yellow| 1614|\n",
      "|   NV|   Red| 1610|\n",
      "|   CA|  Blue| 1603|\n",
      "|   WY|Orange| 1595|\n",
      "|   UT| Green| 1591|\n",
      "|   WY| Brown| 1532|\n",
      "+-----+------+-----+\n",
      "\n",
      "Total Rows = 60\n"
     ]
    }
   ],
   "source": [
    "// Show the resulting aggregations for all the states and colors\n",
    "countMnMDF.show(60)\n",
    "println(s\"Total Rows = ${countMnMDF.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-----+\n",
      "|State| Color|Total|\n",
      "+-----+------+-----+\n",
      "|   CA|Yellow| 1807|\n",
      "|   CA| Green| 1723|\n",
      "|   CA| Brown| 1718|\n",
      "|   CA|Orange| 1657|\n",
      "|   CA|   Red| 1656|\n",
      "|   CA|  Blue| 1603|\n",
      "+-----+------+-----+\n",
      "\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "caCountMnMDF: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [State: string, Color: string ... 1 more field]\r\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Find the aggregate counts for California by filtering\n",
    "val caCountMnMDF = mnmDF\n",
    ".select(\"State\", \"Color\", \"Count\")\n",
    ".where(col(\"State\") === \"CA\")\n",
    ".groupBy(\"State\", \"Color\")\n",
    ".agg(count(\"Count\").alias(\"Total\"))\n",
    ".orderBy(desc(\"Total\"))\n",
    "\n",
    "// Show the resulting aggregations for California\n",
    "caCountMnMDF.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios extra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Descargar el Quijote https://gist.github.com/jsdario/6d6c69398cb0c73111e49f1218960f79\n",
    "\n",
    "Aplicar no solo count (para obtener el número de líneas) y show sino probar distintas sobrecargas del método show (con/sin truncate, indicando/sin indicar num de filas, etc) así como también los métodos, head, take, first (diferencias entre estos 3?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ruta_quijote: String = C:/Users/jorgedario.mendez/OneDrive - Bosonit/Documentos/3. Libro/LearningSparkV2-master/JM Jupyter/el_quijote.txt\r\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val ruta_quijote = \"C:/Users/jorgedario.mendez/OneDrive - Bosonit/Documentos/3. Libro/LearningSparkV2-master/JM Jupyter/el_quijote.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "quijote_df: org.apache.spark.sql.DataFrame = [value: string]\r\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val quijote_df = spark.read.text(ruta_quijote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|DON QUIJOTE DE LA...|\n",
      "|Miguel de Cervant...|\n",
      "|                    |\n",
      "|       PRIMERA PARTE|\n",
      "|CAPI?TULO 1: Que ...|\n",
      "|En un lugar de la...|\n",
      "|Tuvo muchas veces...|\n",
      "|En resolucio?n, e...|\n",
      "|historia ma?s cie...|\n",
      "|Deci?a e?l, que e...|\n",
      "|En efecto, remata...|\n",
      "|Imagina?base el p...|\n",
      "|linaje y patria, ...|\n",
      "|Limpias, pues, su...|\n",
      "|Capi?tulo 2: Que ...|\n",
      "|Hechas, pues, est...|\n",
      "|Estos pensamiento...|\n",
      "|Con estos iba ens...|\n",
      "|Autores hay que d...|\n",
      "|muertos de hambre...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "quijote_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res4: Array[org.apache.spark.sql.Row] = Array([DON QUIJOTE DE LA MANCHA], [Miguel de Cervantes Saavedra], [], [PRIMERA PARTE], [CAPI?TULO 1: Que trata de la condicio?n y ejercicio del famoso hidalgo D. Quijote de la Mancha], [En un lugar de la Mancha, de cuyo nombre no quiero acordarme, no ha mucho tiempo que vivi?a un hidalgo de los de lanza en astillero, adarga antigua, roci?n flaco y galgo corredor. Una olla de algo ma?s vaca que carnero, salpico?n las ma?s noches, duelos y quebrantos los sa?bados, lentejas los viernes, algu?n palomino de an?adidura los domingos, consumi?an las tres partes de su hacienda. El resto della conclui?an sayo de velarte, calzas de velludo para las fiestas con sus pantuflos de lo mismo, los di?as de entre semana se honraba con su vellori de lo ma?s fino. Ten...\r\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quijote_df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res5: Array[org.apache.spark.sql.Row] = Array([DON QUIJOTE DE LA MANCHA], [Miguel de Cervantes Saavedra], [], [PRIMERA PARTE], [CAPI?TULO 1: Que trata de la condicio?n y ejercicio del famoso hidalgo D. Quijote de la Mancha], [En un lugar de la Mancha, de cuyo nombre no quiero acordarme, no ha mucho tiempo que vivi?a un hidalgo de los de lanza en astillero, adarga antigua, roci?n flaco y galgo corredor. Una olla de algo ma?s vaca que carnero, salpico?n las ma?s noches, duelos y quebrantos los sa?bados, lentejas los viernes, algu?n palomino de an?adidura los domingos, consumi?an las tres partes de su hacienda. El resto della conclui?an sayo de velarte, calzas de velludo para las fiestas con sus pantuflos de lo mismo, los di?as de entre semana se honraba con su vellori de lo ma?s fino. Ten...\r\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quijote_df.take(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res6: org.apache.spark.sql.Row = [DON QUIJOTE DE LA MANCHA]\r\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quijote_df.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "// quijote_df.show(6, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "// quijote_df.show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Del ejercicio de M&M aplicar:\n",
    "\n",
    "i. Otras operaciones de agregación como el Max con otro tipo de ordenamiento (descendiente)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prueba1_mnm_df: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [State: string, Color: string ... 1 more field]\r\n"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val prueba1_mnm_df = mnmDF\n",
    ".select(\"State\", \"Color\", \"count\")\n",
    ".where(col(\"State\") === \"CA\" || col(\"State\") === \"WY\")\n",
    ".groupBy(\"State\", \"Color\")\n",
    ".agg(max(\"Count\"))\n",
    ".orderBy(\"Color\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+----------+\n",
      "|State| Color|max(Count)|\n",
      "+-----+------+----------+\n",
      "|   WY|  Blue|       100|\n",
      "|   CA|  Blue|       100|\n",
      "|   CA| Brown|       100|\n",
      "|   WY| Brown|       100|\n",
      "|   WY| Green|       100|\n",
      "|   CA| Green|       100|\n",
      "|   WY|Orange|       100|\n",
      "|   CA|Orange|       100|\n",
      "|   CA|   Red|       100|\n",
      "|   WY|   Red|       100|\n",
      "|   WY|Yellow|       100|\n",
      "|   CA|Yellow|       100|\n",
      "+-----+------+----------+\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "prueba1_mnm_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "max_mnm_df: org.apache.spark.sql.DataFrame = [State: string, max(Count): int]\r\n"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val max_mnm_df = (mnmDF\n",
    ".select(\"State\", \"Color\", \"Count\")\n",
    ".groupBy(\"State\")\n",
    ".agg(max(col(\"Count\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "|State|max(Count)|\n",
      "+-----+----------+\n",
      "|   AZ|       100|\n",
      "|   OR|       100|\n",
      "|   WY|       100|\n",
      "|   NV|       100|\n",
      "|   CA|       100|\n",
      "|   WA|       100|\n",
      "|   NM|       100|\n",
      "|   TX|       100|\n",
      "|   CO|       100|\n",
      "|   UT|       100|\n",
      "+-----+----------+\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "max_mnm_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Stop the SparkSession\n",
    "// spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
