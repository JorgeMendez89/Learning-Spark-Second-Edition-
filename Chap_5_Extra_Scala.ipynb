{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://EM2021002778.bosonit.local:4040\n",
       "SparkContext available as 'sc' (version = 3.1.1, master = local[*], app id = local-1620892133039)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.SparkSession\r\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@35f2dc8\r\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spark = SparkSession\n",
    ".builder\n",
    ".appName(\"cap 5 extra\")\n",
    "//.config(\"spark.jars.packages\", \"com.databricks:spark-avro_2.12:3.1.1\")\n",
    "//.config(\"spark.sql.catalogImplementation\",\"hive\")\n",
    ".enableHiveSupport()\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emplo: org.apache.spark.sql.DataFrame = [emp_no: int, birth_date: date ... 4 more fields]\r\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Read Option 1: Loading data from a JDBC source using load method\n",
    "val emplo = spark\n",
    ".read\n",
    ".format(\"jdbc\")\n",
    ".option(\"url\", \"jdbc:mysql://localhost:3306/employees\")\n",
    ".option(\"driver\", \"com.mysql.jdbc.Driver\")\n",
    ".option(\"dbtable\", \"employees\")\n",
    ".option(\"user\", \"root\")\n",
    ".option(\"password\", \"Bosonit2021!\")\n",
    ".load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "emplo.createOrReplaceTempView(\"emplo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+----------+-----------+------+----------+\n",
      "|emp_no|birth_date|first_name|  last_name|gender| hire_date|\n",
      "+------+----------+----------+-----------+------+----------+\n",
      "| 10001|1953-09-02|    Georgi|    Facello|     M|1986-06-26|\n",
      "| 10002|1964-06-02|   Bezalel|     Simmel|     F|1985-11-21|\n",
      "| 10003|1959-12-03|     Parto|    Bamford|     M|1986-08-28|\n",
      "| 10004|1954-05-01| Chirstian|    Koblick|     M|1986-12-01|\n",
      "| 10005|1955-01-21|   Kyoichi|   Maliniak|     M|1989-09-12|\n",
      "| 10006|1953-04-20|    Anneke|    Preusig|     F|1989-06-02|\n",
      "| 10007|1957-05-23|   Tzvetan|  Zielinski|     F|1989-02-10|\n",
      "| 10008|1958-02-19|    Saniya|   Kalloufi|     M|1994-09-15|\n",
      "| 10009|1952-04-19|    Sumant|       Peac|     F|1985-02-18|\n",
      "| 10010|1963-06-01| Duangkaew|   Piveteau|     F|1989-08-24|\n",
      "| 10011|1953-11-07|      Mary|      Sluis|     F|1990-01-22|\n",
      "| 10012|1960-10-04|  Patricio|  Bridgland|     M|1992-12-18|\n",
      "| 10013|1963-06-07| Eberhardt|     Terkki|     M|1985-10-20|\n",
      "| 10014|1956-02-12|     Berni|      Genin|     M|1987-03-11|\n",
      "| 10015|1959-08-19|  Guoxiang|  Nooteboom|     M|1987-07-02|\n",
      "| 10016|1961-05-02|  Kazuhito|Cappelletti|     M|1995-01-27|\n",
      "| 10017|1958-07-06| Cristinel|  Bouloucos|     F|1993-08-03|\n",
      "| 10018|1954-06-19|  Kazuhide|       Peha|     F|1987-04-03|\n",
      "| 10019|1953-01-23|   Lillian|    Haddadi|     M|1999-04-30|\n",
      "| 10020|1952-12-24|    Mayuko|    Warwick|     M|1991-01-26|\n",
      "+------+----------+----------+-----------+------+----------+\n",
      "only showing top 20 rows\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM emplo\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sala: org.apache.spark.sql.DataFrame = [emp_no: int, salary: int ... 2 more fields]\r\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sala = spark\n",
    ".read\n",
    ".format(\"jdbc\")\n",
    ".option(\"url\", \"jdbc:mysql://localhost:3306/employees\")\n",
    ".option(\"driver\", \"com.mysql.jdbc.Driver\")\n",
    ".option(\"dbtable\", \"salaries\")\n",
    ".option(\"user\", \"root\")\n",
    ".option(\"password\", \"Bosonit2021!\")\n",
    ".load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sala.createOrReplaceTempView(\"sala\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----------+----------+\n",
      "|emp_no|salary| from_date|   to_date|\n",
      "+------+------+----------+----------+\n",
      "| 10001| 60117|1986-06-26|1987-06-26|\n",
      "| 10001| 62102|1987-06-26|1988-06-25|\n",
      "| 10001| 66074|1988-06-25|1989-06-25|\n",
      "| 10001| 66596|1989-06-25|1990-06-25|\n",
      "| 10001| 66961|1990-06-25|1991-06-25|\n",
      "| 10001| 71046|1991-06-25|1992-06-24|\n",
      "| 10001| 74333|1992-06-24|1993-06-24|\n",
      "| 10001| 75286|1993-06-24|1994-06-24|\n",
      "| 10001| 75994|1994-06-24|1995-06-24|\n",
      "| 10001| 76884|1995-06-24|1996-06-23|\n",
      "| 10001| 80013|1996-06-23|1997-06-23|\n",
      "| 10001| 81025|1997-06-23|1998-06-23|\n",
      "| 10001| 81097|1998-06-23|1999-06-23|\n",
      "| 10001| 84917|1999-06-23|2000-06-22|\n",
      "| 10001| 85112|2000-06-22|2001-06-22|\n",
      "| 10001| 85097|2001-06-22|2002-06-22|\n",
      "| 10001| 88958|2002-06-22|9999-01-01|\n",
      "| 10002| 65828|1996-08-03|1997-08-03|\n",
      "| 10002| 65909|1997-08-03|1998-08-03|\n",
      "| 10002| 67534|1998-08-03|1999-08-03|\n",
      "+------+------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM sala\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title: org.apache.spark.sql.DataFrame = [emp_no: int, title: string ... 2 more fields]\r\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val title = spark\n",
    ".read\n",
    ".format(\"jdbc\")\n",
    ".option(\"url\", \"jdbc:mysql://localhost:3306/employees\")\n",
    ".option(\"driver\", \"com.mysql.jdbc.Driver\")\n",
    ".option(\"dbtable\", \"titles\")\n",
    ".option(\"user\", \"root\")\n",
    ".option(\"password\", \"Bosonit2021!\")\n",
    ".load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "title.createOrReplaceTempView(\"title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+----------+----------+\n",
      "|emp_no|             title| from_date|   to_date|\n",
      "+------+------------------+----------+----------+\n",
      "| 10001|   Senior Engineer|1986-06-26|9999-01-01|\n",
      "| 10002|             Staff|1996-08-03|9999-01-01|\n",
      "| 10003|   Senior Engineer|1995-12-03|9999-01-01|\n",
      "| 10004|          Engineer|1986-12-01|1995-12-01|\n",
      "| 10004|   Senior Engineer|1995-12-01|9999-01-01|\n",
      "| 10005|      Senior Staff|1996-09-12|9999-01-01|\n",
      "| 10005|             Staff|1989-09-12|1996-09-12|\n",
      "| 10006|   Senior Engineer|1990-08-05|9999-01-01|\n",
      "| 10007|      Senior Staff|1996-02-11|9999-01-01|\n",
      "| 10007|             Staff|1989-02-10|1996-02-11|\n",
      "| 10008|Assistant Engineer|1998-03-11|2000-07-31|\n",
      "| 10009|Assistant Engineer|1985-02-18|1990-02-18|\n",
      "| 10009|          Engineer|1990-02-18|1995-02-18|\n",
      "| 10009|   Senior Engineer|1995-02-18|9999-01-01|\n",
      "| 10010|          Engineer|1996-11-24|9999-01-01|\n",
      "| 10011|             Staff|1990-01-22|1996-11-09|\n",
      "| 10012|          Engineer|1992-12-18|2000-12-18|\n",
      "| 10012|   Senior Engineer|2000-12-18|9999-01-01|\n",
      "| 10013|      Senior Staff|1985-10-20|9999-01-01|\n",
      "| 10014|          Engineer|1993-12-29|9999-01-01|\n",
      "+------+------------------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM title\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JOIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+----------+---------+------+----------------+\n",
      "|emp_no|birth_date|first_name|last_name|salary|           title|\n",
      "+------+----------+----------+---------+------+----------------+\n",
      "| 10206|1960-09-19|  Alassane|  Iwayama| 40000|Technique Leader|\n",
      "| 10206|1960-09-19|  Alassane|  Iwayama| 43519|Technique Leader|\n",
      "| 10206|1960-09-19|  Alassane|  Iwayama| 46265|Technique Leader|\n",
      "| 10206|1960-09-19|  Alassane|  Iwayama| 46865|Technique Leader|\n",
      "| 10206|1960-09-19|  Alassane|  Iwayama| 47837|Technique Leader|\n",
      "| 10206|1960-09-19|  Alassane|  Iwayama| 52042|Technique Leader|\n",
      "| 10206|1960-09-19|  Alassane|  Iwayama| 52370|Technique Leader|\n",
      "| 10206|1960-09-19|  Alassane|  Iwayama| 53202|Technique Leader|\n",
      "| 10206|1960-09-19|  Alassane|  Iwayama| 56087|Technique Leader|\n",
      "| 10206|1960-09-19|  Alassane|  Iwayama| 59252|Technique Leader|\n",
      "| 10206|1960-09-19|  Alassane|  Iwayama| 62716|Technique Leader|\n",
      "| 10206|1960-09-19|  Alassane|  Iwayama| 67137|Technique Leader|\n",
      "| 10206|1960-09-19|  Alassane|  Iwayama| 67944|Technique Leader|\n",
      "| 10206|1960-09-19|  Alassane|  Iwayama| 67588|Technique Leader|\n",
      "| 10206|1960-09-19|  Alassane|  Iwayama| 71052|Technique Leader|\n",
      "| 10362|1963-09-16|   Shalesh|  dAstous| 40000|    Senior Staff|\n",
      "| 10362|1963-09-16|   Shalesh|  dAstous| 44091|    Senior Staff|\n",
      "| 10362|1963-09-16|   Shalesh|  dAstous| 45546|    Senior Staff|\n",
      "| 10362|1963-09-16|   Shalesh|  dAstous| 49296|    Senior Staff|\n",
      "| 10362|1963-09-16|   Shalesh|  dAstous| 48889|    Senior Staff|\n",
      "+------+----------+----------+---------+------+----------------+\n",
      "only showing top 20 rows\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select emplo.emp_no, emplo.birth_date, emplo.first_name, emplo.last_name, sala.salary, title.title \n",
    "from emplo inner join sala on emplo.emp_no = sala.emp_no\n",
    "inner join title on emplo.emp_no = title.emp_no\"\"\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
